====================================================================================================================================================================
                                           REDHAT CEPH STORAGE ARCTECTURE
====================================================================================================================================================================
Chapter-1:THE CEPH ARCHITECTURE
================================
1.Introduction:
----------------
Red Hat Ceph Storage cluster is a distributed data object store designed to provide excellent performance, reliability and scalability.
For example:
------------
APIs in many languages (C/C++, Java, Python) 
RESTful interfaces (S3/Swift)
Block device interface
Filesystem interface

At the heart of every Ceph deployment is the Red Hat Ceph Storage cluster. It consists of three types of daemons:

Ceph OSD Daemon: 
----------------
Ceph OSDs store data on behalf of Ceph clients. Additionally, Ceph OSDs utilize the CPU, memory and networking of Ceph nodes to perform data replication, 
erasure coding, rebalancing, recovery, monitoring and reporting functions.

Ceph Monitor: 
--------------
A Ceph Monitor maintains a master copy of the Red Hat Ceph Storage cluster map with the current state of the Red Hat Ceph Storage cluster. 
Monitors require high consistency, and use Paxos to ensure agreement about the state of the Red Hat Ceph Storage cluster.

Ceph Manager:
--------------
The Ceph Manager maintains detailed information about placement groups, process metadata and host metadata in lieu of the Ceph Monitor—​significantly 
improving performance at scale. The Ceph Manager handles execution of many of the read-only Ceph CLI queries, such as placement group statistics.
The Ceph Manager also provides the RESTful monitoring APIs.

Ceph client interfaces read data from and write data to the Red Hat Ceph Storage cluster. 
Clients need the following data to communicate with the Red Hat Ceph Storage cluster:

- The Ceph configuration file, or the cluster name (usually ceph) and the monitor address 
- The pool name
- The user name and the path to the secret key.

Ceph clients maintain object IDs and the pool names where they store the objects. 
However, they do not need to maintain an object-to-OSD index or communicate with a centralized object index to look up object locations. 
To store and retrieve data, Ceph clients access a Ceph Monitor and retrieve the latest copy of the Red Hat Ceph Storage cluster map.
Then, Ceph clients provide an object name and pool name to librados, which computes an object’s placement group and the primary OSD
for storing and retrieving data using the CRUSH (Controlled Replication Under Scalable Hashing) algorithm. The Ceph client connects
to the primary OSD where it may perform read and write operations. There is no intermediary server, broker or bus between the client and the OSD.

When an OSD stores data, it receives data from a Ceph client—​whether the client is a Ceph Block Device, 
a Ceph Object Gateway, a Ceph Filesystem or another interface—​and it stores the data as an object.

Ceph clients define the semantics for the client’s data format. For example, the Ceph block device maps a block device image to a series of
objects stored across the cluster.
===============================================================================================================================================================================================
Chapter 2:THE CORE CEPH COMPONENTS
====================================
A Red Hat Ceph Storage cluster can have a large number of Ceph nodes for limitless scalability, high availability and performance.
Each node leverages non-proprietary hardware and intelligent Ceph daemons that communicate with each other to:

- Write and read data
- Compress data
- Ensure durability by replicating or erasure coding data
- Monitor and report on cluster health—​also called 'heartbeating' 
- Redistribute data dynamically—​also called 'backfilling'
- Ensure data integrity; and,
- Recover from failures.


To the Ceph client interface that reads and writes data, a Red Hat Ceph Storage cluster looks like a simple pool where it stores data.
However, librados and the storage cluster perform many complex operations in a manner that is completely transparent to the client interface.
Ceph clients and Ceph OSDs both use the CRUSH (Controlled Replication Under Scalable Hashing) algorithm. 


2.1: CEPH POOLS:
-----------------
- The Ceph storage cluster stores data objects in logical partitions called 'Pools.' 
- Ceph administrators can create pools for particular types of data, such as for block devices, 
  object gateways, or simply just to separate one group of users from another.
- From the perspective of a Ceph client, the storage cluster is very simple 
- it always connects to a storage pool in the Ceph storage cluster. 
- The client specifies the pool name, a user and a secret key, so the pool appears to act as a logical partition with access controls to its data objects.

Ceph pools define:
-------------------
Pool Type: The data durability method is pool-wide,
---------

Placement Groups:
------------------
- a Ceph pool might store millions of data objects or more. 
- Ceph must handle many types of operations, including data durability via replicas or erasure code chunks, data integrity by scrubbing or CRC checks, replication, 
  rebalancing and recovery. 
- Ceph addresses this bottleneck by sharding a pool into placement groups.
- The CRUSH algorithm computes the placement group for storing an object and computes the Acting Set of OSDs for the placement group. 
- CRUSH puts each object into a placement group. Then, CRUSH stores each placement group in a set of OSDs.
- System administrators set the placement group count when creating or modifying a pool.

CRUSH Ruleset: 
--------------
CRUSH enables Ceph OSDs to store object copies across failure domains
For example, copies of an object may get stored in different server rooms, aisles, racks and nodes. 
If a large part of a cluster fails, such as a rack, the cluster can still operate in a degraded state until the cluster recovers.

2.2.CEPH AUTHENTICATION:
--------------------------
- To identify users and protect against man-in-the-middle attacks, Ceph provides its cephx authentication system, which authenticates users and daemons.
- Cephx uses shared secret keys for authentication, meaning both the client and the monitor cluster have a copy of the client’s secret key. 
- The authentication protocol enables both parties to prove to each other that they have a copy of the key without actually revealing it
- his provides mutual authentication, which means the cluster is sure the user possesses the secret key, and the user is sure that the cluster has a copy of the secret key.

CEPHX: The cephx authentication protocol operates in a manner similar to Kerberos.
------

2.3. CEPH PLACEMENT GROUPS:
----------------------------
- Storing millions of objects in a cluster and managing them individually is resource intensive. So Ceph uses placement groups (PGs) to make managing a huge number of objects more efficient.
- A PG is a subset of a pool that serves to contain a collection of objects. 
- Ceph shards a pool into a series of PGs. 
- Then, the CRUSH algorithm takes the cluster map and the status of the cluster into account and distributes the PGs evenly and pseudo-randomly to OSDs in the cluster.

- When a system administrator creates a pool, CRUSH creates a user-defined number of PGs for the pool.
- Ceph ensures against data loss by storing replicas of an object Since Ceph stores objects or erasure code chunks of an object within PGs,
- Ceph replicates each PG in a set of OSDs called the "Acting Set" for each copy of an object or each erasure code chunk of an object.
- A system administrator can determine the number of PGs in a pool and the number of replicas

The CRUSH algorithm and PGs make Ceph dynamic. Changes in the cluster map or the cluster state may result in Ceph moving PGs from one OSD to another automatically.
Examples:
----------
Expanding the Cluster & An OSD Fails
By managing millions of objects within the context of hundreds to thousands of PGs, the Ceph storage cluster can grow, shrink and recover from failure efficiently.

For Ceph clients, the CRUSH algorithm via librados makes the process of reading and writing objects very simple. A Ceph client simply writes an object to 
a pool or reads an object from a pool. The primary OSD in the acting set can write replicas of the object or erasure code chunks of the object to the secondary 
OSDs in the acting set on behalf of the Ceph client.

The Ceph client via librados connects directly to the primary OSD within an acting set when writing and reading objects. Since I/O operations do not use a centralized broker, 
network oversubscription is typically NOT an issue with Ceph.

2.4. CEPH CRUSH RULESET
-------------------------
Ceph assigns a CRUSH ruleset to a pool.
When a Ceph client stores or retrieves data in a pool, Ceph identifies the CRUSH ruleset, 
As Ceph processes the CRUSH rule, it identifies the primary OSD that contains the placement group for an object. 
That enables the client to connect directly to the OSD, access the placement group and read or write object data.

To map placement groups to OSDs, a CRUSH map defines a hierarchical list of bucket types

2.5. CEPH INPUT/OUTPUT OPERATIONS:
-----------------------------------
- Ceph clients retrieve a 'Cluster Map' from a Ceph monitor, bind to a pool, and perform input/output(I/O) on objects within placement groups in the pool. 
- The pool’s CRUSH ruleset and the number of placement groups are the main factors that determine how Ceph will place the data. 
- With the latest version of the cluster map, the client knows about all of the monitors and OSDs in the cluster and their current state.

The only inputs required by the client are the object ID and the pool name. It is simple: Ceph stores data in named pools. 
When a client wants to store a named object in a pool it takes the object name, a hash code, the number of PGs in the pool 
and the pool name as inputs; then, CRUSH (Controlled Replication Under Scalable Hashing) calculates the ID of the placement 
group and the primary OSD for the placement group.

Ceph clients use the following steps to compute PG IDs:
-------------------------------------------------------
1. TheclientinputsthepoolIDandtheobjectID.Forexample,pool=liverpoolandobject-id= john.
2. CRUSHtakestheobjectIDandhashesit.
3. CRUSHcalculatesthehashmoduloofthenumberofPGstogetaPGID.Forexample,58.
4. CRUSHcalculatestheprimaryOSDcorrespondingtothePGID.
5. TheclientgetsthepoolIDgiventhepoolname.Forexample,thepool"liverpool"ispoolnumber 4.
6. TheclientprependsthepoolIDtothePGID.Forexample,4.58.
7. Theclientperformsanobjectoperationsuchaswrite,read,ordeletebycommunicatingdirectly
with the Primary OSD in the Acting Set.

2.6. CEPH REPLICATION:
----------------------
- Like Ceph clients, Ceph OSDs can contact Ceph monitors to retrieve the latest copy of the cluster map.
- Ceph OSDs also use the CRUSH algorithm, but they use it to compute where to store replicas of objects
- In a typical write scenario, a Ceph client uses the CRUSH algorithm to compute the placement group ID and the primary OSD in the Acting Set for an object.
- When the client writes the object to the primary OSD, the primary OSD finds the number of replicas that it should store. 
- The value is found in the osd_pool_default_size setting
- primary osd replicates data to other osds as per ur replication count.

Data copies:
------------
In a replicated storage pool, Ceph needs multiple copies of an object to operate in a degraded state. 
Ideally, a Ceph storage cluster enables a client to read and write data even if one of the OSDs in an acting set fails. 
For this reason, Ceph defaults to making three copies of an object with a minimum of two copies clean for write operations.
Ceph will still preserve data even if two OSDs fail. However, it will interrupt write operations.

2.7. CEPH ERASURE CODING:
---------------------------


2.8. CEPH OBJECTSTORE:
----------------------------
- ObjectStore provides a low-level interface to an OSD’s raw block device
- When a client reads or writes data, it interacts with the ObjectStore interface.
- An object stored in the storage cluster has a unique identifier, object data and metadata. 

Ceph implements several concrete methods for storing data:
FileStore: A production grade implementation using a filesystem to store object data.
BlueStore: A production grade implementation using a raw block device to store object data.
Memstore: A developer implementation for testing read/write operations directly in RAM.
K/V Store: An internal implementation for Ceph’s use of key/value databases.

Since administrators will generally only address BlueStore,

2.9. CEPH BLUESTORE:
---------------------
- BlueStore is the next generation storage implementation for Ceph.
- Ceph reveals some of the limitations of the FileStore storage implementation. 
- Blue store beats all limitaations of filestore.

BlueStore stores data as:
--------------------------
Object Data
Block Database
Write-ahead Log

2.10. CEPH SELF MANAGEMENT OPERATIONS:
---------------------------------------
- Ceph clusters perform a lot of self monitoring and management operations automatically.
- For example, Ceph OSDs can check the cluster health and report back to the Ceph monitors.
  By using CRUSH to assign objects to placement groups and placement groups to a set of OSDs, 
  Ceph OSDs can use the CRUSH algorithm to rebalance the cluster or recover from OSD failures dynamically.

2.11. CEPH HEARTBEAT:
----------------------
Ceph OSDs join a cluster and report to Ceph Monitors on their status. 
At the lowest level, the Ceph OSD status is up or down reflecting whether or not it is running and able to service Ceph client requests. 
If a Ceph OSD is down and in the Ceph storage cluster, this status may indicate the failure of the Ceph OSD. 
If a Ceph OSD is not running for example, it crashes—​the Ceph OSD cannot notify the Ceph Monitor that it is down. 
The Ceph Monitor can ping a Ceph OSD daemon periodically to ensure that it is running.
However, heartbeating also empowers Ceph OSDs to determine if a neighboring OSD is down, to update the cluster map and to report it to the Ceph Monitors.
This means that Ceph Monitors can remain light weight processes.

2.12.CEPH PEERING
--------------------
Ceph stores copies of placement groups on multiple OSDs. Each copy of a placement group has a status. 
These OSDs "peer" or check each other to ensure that they agree on the status of each copy of the PG. 
Peering issues usually resolve themselves.


2.13. CEPH REBALANCING AND RECOVERY:
--------------------------------------
When an administrator adds a Ceph OSD to a Ceph storage cluster, Ceph updates the cluster map.
This change to the cluster map also changes object placement, because the modified cluster map changes an input for the CRUSH calculations. 

2.14. CEPH DATA INTEGRITY:
--------------------------
As part of maintaining data integrity, Ceph provides numerous mechanisms to guard against bad disk sectors and bit rot.

Scrubbing: Ceph OSD Daemons can scrub objects within placement groups. 
That is, Ceph OSD Daemons can compare object metadata in one placement group with its replicas in placement groups stored on other OSDs. 
Scrubbing—​usually performed daily—​catches bugs or storage errors. Ceph OSD Daemons also perform deeper scrubbing by comparing data in objects bit- for-bit. 
Deep scrubbing—​usually performed weekly—​finds bad sectors on a drive that weren’t apparent in a light scrub.

CRCChecks:InRedHatCephStorage4whenusing BlueStore,Cephcanensuredataintegrity by conducting a cyclical redundancy check (CRC) on write operations; 
then, store the CRC value in the block database. On read operations, Ceph can retrieve the CRC value from the block database and compare 
it with the generated CRC of the retrieved data to ensure data integrity instantly.


2.15.CEPH HIGH AVAILABILITY
------------------------------
In addition to the high scalability enabled by the CRUSH algorithm, Ceph must also maintain high availability. 
This means that Ceph clients must be able to read and write data even when the cluster is in a degraded state, or when a monitor fails.

2.16. CLUSTERING THE CEPH MONITOR
---------------------------------
Before Ceph clients can read or write data, they must contact a Ceph Monitor to obtain the most recent copy of the cluster map. 
A Red Hat Ceph Storage cluster can operate with a single monitor; however, this introduces a single point of failure. 
That is, if the monitor goes down, Ceph clients cannot read or write data.

2.17. CEPH HIGH AVAILABILITY
-----------------------------
In addition to the high scalability enabled by the CRUSH algorithm, Ceph must also maintain high availability. 
This means that Ceph clients must be able to read and write data even when the cluster is in a degraded state, or when a monitor fails.

=======================================================================================================================================================================

CHAPTER-3: CEPH CLIENT COMPONENTS:
===================================
- Ceph clients differ in their materially in how they present data storage interfaces.
- A Ceph block device presents block storage that mounts just like a physical storage drive
- A Ceph gateway presents an object storage service with S3-compliant
- Swift-compliant RESTful interfaces with its own user management

all Ceph clients use the Reliable Autonomic Distributed Object Store (RADOS) protocol to interact with the Red Hat Ceph Storage cluster.

They all have the same basic needs:
----------------------------------
The Ceph configuration file, and the Ceph monitor address. 
The pool name.
The user name and the path to the secret key.


3.1.CEPH CLIENT NATIVE PROTOCOL:
------------------------------------
- The Ceph Storage Cluster provides a simple object storage interface with asynchronous communication capability. 
- The interface provides direct, parallel access to objects throughout the cluster.

Pool Operations 
Snapshots 
Read/Write Objects
Create or Remove
Entire Object or Byte Range 
Append or Truncate
Create/Set/Get/Remove XATTRs Create/Set/Get/Remove 
Key/Value Pairs Compound operations and dual-ack semantics

3.2. CEPH CLIENT OBJECT WATCH AND NOTIFY:
-----------------------------------------
- A Ceph client can register a persistent interest with an object and keep a session to the primary OSD open. 
- The client can send a notification message and payload to all watchers and receive notification when the watchers receive the notification.
- This enables a client to use any object as a synchronization/communication channel.

3.3. CEPH CLIENT MANDATORY EXCLUSIVE LOCKS:
--------------------------------------------






















































































































































































































































































